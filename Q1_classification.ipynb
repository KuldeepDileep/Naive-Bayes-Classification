{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Q1_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5znncbKrr0K"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB4T-l3Orr0c"
      },
      "source": [
        "def load_file(fileName):\n",
        "    dataset = pd.read_table(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1fUIXcBrr0s"
      },
      "source": [
        "# preprocess creates the term frequency matrix for the review data set\n",
        "def preprocess(data):\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    data = count_vectorizer.fit_transform(data)\n",
        "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\n",
        "    ft = count_vectorizer.get_feature_names() \n",
        "    #print(list(map(lambda row:dict(zip(ft,row)),data.toarray())))\n",
        "    data = pd.DataFrame(data.toarray(),columns=ft)\n",
        "    #print(df.columns)\n",
        "    #print(df)\n",
        "    return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Wyh3durr02"
      },
      "source": [
        "def learn_model(data,target):\n",
        "    classifier = None\n",
        "    #Your custom implementation of NaiveBayes classifier will go here.\n",
        "    #Computing prior(pc):\n",
        "    pc = {}\n",
        "    pwc = {}\n",
        "    freq_class = {}\n",
        "    c = []\n",
        "    total = 0\n",
        "    unq_lst = list(target.unique())\n",
        "    count_lst = target.value_counts()\n",
        "    #print(count_lst)\n",
        "    for i in count_lst.index:\n",
        "        freq_class[i] = count_lst[i] \n",
        "        total+=count_lst[i]\n",
        "    for i in freq_class.items():\n",
        "        prob = i[1]/total\n",
        "        pc[i[0]] = prob\n",
        "    #print(unq_lst)\n",
        "    #Conditional prob of each word attribute(P(w|c)):\n",
        "    #print(data.shape[0])\n",
        "    #print(target.shape)\n",
        "    #print(target)\n",
        "    #for i in data.index:\n",
        "    #  print(i)\n",
        "    unq_dic = {}\n",
        "    for i in unq_lst:\n",
        "        unq_dic[i] = 0\n",
        "    print(unq_dic)\n",
        "    #for i in range(data.shape[0]):\n",
        "        #data[0][(0,8209)]\n",
        "        \n",
        "        #print(target[i])\n",
        "        #print(i)\n",
        "\n",
        "    return classifier"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j4y_O3Krr1B"
      },
      "source": [
        "def classify(classifier, testdata):\n",
        "    \n",
        "    predicted_val=[]\n",
        "    #Your code to classify test data using the learned model will go here\n",
        "    \n",
        "    \n",
        "    return predicted_val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu5VNDMbrr1N"
      },
      "source": [
        "def evaluate(actual_class, predicted_class):\n",
        "        \n",
        "    accuracy = -1    \n",
        "    #Your code to evaluate the model will go here. The code will print overall model's accuracy and precision \n",
        "    #and recall for each class label.\n",
        "    \n",
        "    \n",
        "    print(\"The accuracy score is :\",accuracy)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nphWMIsarr1X",
        "outputId": "9ea9d6f2-b904-4264-9e94-bc7a18655776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\n",
        "print(\"Loading data.....\")\n",
        "dataset = load_file(\"TextClassification_Data.csv\")\n",
        "#print(dataset['categories'])\n",
        "target = dataset['categories']\n",
        "data = dataset[features[0]].fillna(\" \")\n",
        "#target = target.to_list()\n",
        "#print(target)\n",
        "#data,target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\n",
        "print(\"preprocessing data.....\")\n",
        "word_vectors = preprocess(data)\n",
        "#word_vectors = word_vectors.toarray()\n",
        "#word_vectors = word_vectors.toarray()\n",
        "#word_vectors = np.array(word_vectors)\n",
        "#print(word_vectors.)\n",
        "#print(word_vectors[1000:2000])\n",
        "#print(word_vectors[0][1000:2000])\n",
        "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\n",
        "#print(np.where(trainingX.toarray() == trainingX.toarray()[0][0]))\n",
        "print(trainingX)\n",
        "''''print(lst3[0])\n",
        "print(trainingX[1][(0, 8209)])\n",
        "print(trainingX)\n",
        "print(\"Learning model.....\")'''\n",
        "model = learn_model(trainingX,trainingY)\n",
        "#print(trainingY)\n",
        "print(\"Classifying test data......\")      \n",
        "predictedY = classify(model, testX)\n",
        "#print(trainingX.toarray())\n",
        "print(\"Evaluating results.....\")\n",
        "evaluate(testY,predictedY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data.....\n",
            "preprocessing data.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Da20Al2rr1k"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}